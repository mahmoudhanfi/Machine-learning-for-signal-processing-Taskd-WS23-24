{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Programming Task: Digit recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Complete the code for the ConvNet class given below using the network description from supplement pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # First layer: Convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layer: 20 * 12 * 12 input features, 100 output features\n",
    "        self.fc1 = nn.Linear(20 * 12 * 12, 100)\n",
    "        # Final fully connected layer: 100 input features, 10 output features for class probabilities\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layer, followed by ReLU, then max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Flatten the tensor\n",
    "        x = x.view(-1, 20 * 12 * 12)\n",
    "        # Apply first fully connected layer with ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply final fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2880, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Train the CNN and observe the difference in performance in comparison to the feed-forward\n",
    "network from the task 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper parameters.\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the loss function and the optimization criteria\n",
    "\n",
    "# Initialize the ConvNet\n",
    "model = ConvNet()\n",
    "\n",
    "# Set the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.3760\n",
      "Epoch [1/5], Step [200/938], Loss: 0.1212\n",
      "Epoch [1/5], Step [300/938], Loss: 0.0644\n",
      "Epoch [1/5], Step [400/938], Loss: 0.1728\n",
      "Epoch [1/5], Step [500/938], Loss: 0.0557\n",
      "Epoch [1/5], Step [600/938], Loss: 0.0801\n",
      "Epoch [1/5], Step [700/938], Loss: 0.1719\n",
      "Epoch [1/5], Step [800/938], Loss: 0.1763\n",
      "Epoch [1/5], Step [900/938], Loss: 0.1053\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0483\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0606\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0834\n",
      "Epoch [2/5], Step [400/938], Loss: 0.0546\n",
      "Epoch [2/5], Step [500/938], Loss: 0.2247\n",
      "Epoch [2/5], Step [600/938], Loss: 0.0675\n",
      "Epoch [2/5], Step [700/938], Loss: 0.0689\n",
      "Epoch [2/5], Step [800/938], Loss: 0.1246\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0110\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0529\n",
      "Epoch [3/5], Step [200/938], Loss: 0.2956\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0879\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0076\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0750\n",
      "Epoch [3/5], Step [600/938], Loss: 0.0968\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0482\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0974\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1308\n",
      "Epoch [4/5], Step [100/938], Loss: 0.0036\n",
      "Epoch [4/5], Step [200/938], Loss: 0.0158\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0007\n",
      "Epoch [4/5], Step [400/938], Loss: 0.1114\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0017\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0065\n",
      "Epoch [4/5], Step [700/938], Loss: 0.1102\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0138\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0932\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0166\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0021\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0126\n",
      "Epoch [5/5], Step [400/938], Loss: 0.1237\n",
      "Epoch [5/5], Step [500/938], Loss: 0.3137\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0014\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1271\n",
      "Epoch [5/5], Step [800/938], Loss: 0.1120\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0778\n"
     ]
    }
   ],
   "source": [
    "# Run the main training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.06%\n"
     ]
    }
   ],
   "source": [
    "# Run the testing loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += targets.size(0)\n",
    "        total_correct += (predicted == targets).sum().item()\n",
    "\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f'Accuracy of the network on the 10000 test images: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Calculate the number of learnable parameters and the output shape in each layer. Verify your\n",
    "answers with model summary. (Refer last cell of the tutorial notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ConvNet                                  [1, 10]                   --\n",
      "├─Conv2d: 1-1                            [1, 20, 24, 24]           520\n",
      "├─MaxPool2d: 1-2                         [1, 20, 12, 12]           --\n",
      "├─Linear: 1-3                            [1, 100]                  288,100\n",
      "├─Linear: 1-4                            [1, 10]                   1,010\n",
      "==========================================================================================\n",
      "Total params: 289,630\n",
      "Trainable params: 289,630\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.59\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.09\n",
      "Params size (MB): 1.16\n",
      "Estimated Total Size (MB): 1.25\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of learnable parameters and the output shape in each layer\n",
    "print(summary(model, input_size=(1, 1, 28, 28)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7c617624a7fd88b4018bd9e75be0d58c4afb6a334791d511af9b9a5162b5af2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
